{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsv4jGuU89rX"
   },
   "source": [
    "# Vision Workshop - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "827c41ab1a12"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Vision Workshop](https://github.com/mblanc/vision-workshop) is a series of labs on how to build an image classification system on Google Cloud. Throughout the Vision Workshop labs, you will learn how to read image data stored in data lake, perform exploratory data analysis (EDA), train a model, register your model in a model registry, evaluate your model, deploy your model to an endpoint, do real-time inference on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45f6e923dc75"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, you will perform exploratory data analysis on the historical bank transactions stored in BigQuery. Please make sure you have completed the [environment setup notebook](00_environment_setup.ipynb) prior to running this notebook.\n",
    "\n",
    "This lab uses the following Google Cloud services and resources:\n",
    "\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai/)\n",
    "- [Google Cloud Storage](https://cloud.google.com/storage)\n",
    "\n",
    "Steps performed in this notebook:\n",
    "\n",
    "- Read data from Google Cloud Storage\n",
    "- Calculate summary statistics across image datasets\n",
    "- Display samples of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b5e2e2a7bdb"
   },
   "source": [
    "### Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04c1dae4ca17"
   },
   "source": [
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing), and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration settings from the setup notebook\n",
    "\n",
    "Set the constants used in this notebook and load the config settings from the `00_environment_setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-vision-workshop\"\n",
    "config = !gsutil cat gs://{BUCKET_NAME}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11d8e5a98a80"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c4746a0c78c"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import io\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dde60686aa82"
   },
   "source": [
    "### Exploratory data analysis of image dataset in Google Cloud Storage\n",
    "\n",
    "In this section, you'll explore some of the Vision Workshop data by running queries and creating a few plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client() \n",
    "\n",
    "# Implicit environment set up\n",
    "# with explicit set up:\n",
    "# client = storage.Client.from_service_account_json('key-file-location')\n",
    "\n",
    "blobs = list(client.list_blobs(BUCKET_NAME, prefix='flowers/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many images per label do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [os.path.split(os.path.dirname(blob.name))[1] for blob in blobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(labels)\n",
    "\n",
    "plt.bar(counter.keys(), counter.values(), width = .5);\n",
    "plt.title(\"Number of Images by Class\");\n",
    "plt.xlabel('Class Name');\n",
    "plt.ylabel('# Images');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the dimensions of the images per label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dims(blob):\n",
    "    '''Returns dimenstions for an RBG image'''\n",
    "    image_data = blob.download_as_bytes()\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    arr = np.array(image)\n",
    "    h,w,d = arr.shape\n",
    "    return h,w\n",
    "\n",
    "for label in set(labels):\n",
    "    blobs = list(client.list_blobs(BUCKET_NAME, prefix=f'flowers/{label}/'))[:20]\n",
    "    my_values = tqdm(blobs)\n",
    "    dims = list(map(get_dims, my_values))\n",
    "    dim_df = pd.DataFrame(dims, columns=['height', 'width'])\n",
    "    sizes = dim_df.groupby(['height', 'width']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "    sizes.plot.scatter(x='width', y='height')\n",
    "    plt.title('Image Sizes (pixels) | {}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some images per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images displayed 4x4\n",
    "nrows = 2\n",
    "ncols = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_sample(label):\n",
    "    '''display 4x4 images'''\n",
    "    blobs = list(client.list_blobs(BUCKET_NAME, prefix=f'flowers/{label}/'))[:4]\n",
    "    fig = plt.gcf()\n",
    "    plt.title(label)\n",
    "    fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "    for i, blob in enumerate(blobs):\n",
    "        sp = plt.subplot(nrows, ncols, i + 1)\n",
    "        sp.axis('Off')\n",
    "        image_data = blob.download_as_bytes()\n",
    "        image = np.array(Image.open(io.BytesIO(image_data)))\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in set(labels):\n",
    "    print(label)\n",
    "    show_image_sample(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n",
    "\n",
    "Now you can go to the next notebook `vertex_ai/03_managed_dataset_and_automl.ipynb`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_exploratory_data_analysis.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
